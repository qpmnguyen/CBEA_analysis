#!/bin/bash -l
# Define names and job files
#SBATCH --job-name=simulation_dat_310
#SBATCH --output=/dartfs-hpc/rc/home/k/f00345k/research/teailr/teailr/analyses/simulations_diff_ab/.future/20210611_183856-0ulnGG/simulation_dat_310_89070590/logs/job55ddbfa62375ba4a23dc57013adcbcda.log
#SBATCH --error=/dartfs-hpc/rc/home/k/f00345k/research/teailr/teailr/analyses/simulations_diff_ab/.future/20210611_183856-0ulnGG/simulation_dat_310_89070590/logs/job55ddbfa62375ba4a23dc57013adcbcda.log
# Define time and resources
#SBATCH --time=20:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=5
#SBATCH --mem-per-cpu=4000
#SBATCH --partition=standard
# Array options look at the slurm_simple.tmpl file on the batchtools website
#SBATCH --mail-user=Quang.P.Nguyen.GR@dartmouth.edu
#SBATCH --mail-type=BEGIN,END,FAIL
# By default, SLURM scripts execute in your home directory, not the
# directory from which they were submitted.
cd $SLURM_SUBMIT_DIR
export DEBUGME=
Rscript -e 'batchtools::doJobCollection("/dartfs-hpc/rc/home/k/f00345k/research/teailr/teailr/analyses/simulations_diff_ab/.future/20210611_183856-0ulnGG/simulation_dat_310_89070590/jobs/job55ddbfa62375ba4a23dc57013adcbcda.rds")'
